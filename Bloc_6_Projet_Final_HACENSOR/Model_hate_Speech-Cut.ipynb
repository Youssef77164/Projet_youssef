{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1eca22",
   "metadata": {
    "id": "ec5d5d59-2d17-46a3-8b66-f0f5eb70f6af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.11.2-py3-none-any.whl (292 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement as (from versions: none)\n",
      "ERROR: No matching distribution found for as\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\conta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy==3.2.0 -q\n",
    "!pip install tensorflow -q\n",
    "!pip install matplotlib -q\n",
    "!pip install pyspellchecker -q\n",
    "!pip install nltk -q\n",
    "!pip install seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "import time\n",
    "from multiprocessing import  Pool\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import string\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, GRU, LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, SimpleRNN,Dense\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c3e9d0a",
   "metadata": {
    "id": "81354634-d496-487e-8327-4a26e5376bf3"
   },
   "outputs": [],
   "source": [
    "speech1 = pd.read_csv('train_data2.csv', index_col = 'id')\n",
    "\n",
    "#Second dataset to balance the first one\n",
    "speech2 = pd.read_csv('labeled_data.csv', index_col = 'Unnamed: 0') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ecc0a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31962</th>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "id                                                             \n",
       "1          0   @user when a father is dysfunctional and is s...\n",
       "2          0  @user @user thanks for #lyft credit i can't us...\n",
       "3          0                                bihday your majesty\n",
       "4          0  #model   i love u take with u all the time in ...\n",
       "5          0             factsguide: society now    #motivation\n",
       "...      ...                                                ...\n",
       "31958      0  ate @user isz that youuu?ðððððð...\n",
       "31959      0    to see nina turner on the airwaves trying to...\n",
       "31960      0  listening to sad songs on a monday morning otw...\n",
       "31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be3aa1d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1637179872264,
     "user": {
      "displayName": "Youss BBB",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04616849028342739253"
     },
     "user_tz": -60
    },
    "id": "200394e5-2704-40eb-a87c-7776257dd90e",
    "outputId": "d672a172-7cc6-46cc-a41f-f350e290da1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech1['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf1044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b46c5c8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 78,
     "status": "ok",
     "timestamp": 1637179872265,
     "user": {
      "displayName": "Youss BBB",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04616849028342739253"
     },
     "user_tz": -60
    },
    "id": "a820daa6-821f-437a-a69a-e0b4926d11f6",
    "outputId": "b79d3d33-8276-4004-9b23-531538762012"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>\" momma said no pussy cats inside my doghouse \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>\"@Addicted2Guys: -SimplyAddictedToGuys http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>\"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>\"@Allyhaaaaa: Lemmie eat a Oreo &amp;amp; do these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25249</th>\n",
       "      <td>1</td>\n",
       "      <td>yaya ho.. cute avi tho RT @ViVaLa_Ari I had no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25250</th>\n",
       "      <td>1</td>\n",
       "      <td>yea so about @N_tel 's new friend.. all my fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25280</th>\n",
       "      <td>1</td>\n",
       "      <td>you know what they say, the early bird gets th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25292</th>\n",
       "      <td>1</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25296</th>\n",
       "      <td>1</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "0          1  !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "40         1    \" momma said no pussy cats inside my doghouse \"\n",
       "63         1  \"@Addicted2Guys: -SimplyAddictedToGuys http://...\n",
       "66         1  \"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...\n",
       "67         1  \"@Allyhaaaaa: Lemmie eat a Oreo &amp; do these...\n",
       "...      ...                                                ...\n",
       "25249      1  yaya ho.. cute avi tho RT @ViVaLa_Ari I had no...\n",
       "25250      1  yea so about @N_tel 's new friend.. all my fri...\n",
       "25280      1  you know what they say, the early bird gets th...\n",
       "25292      1  you've gone and broke the wrong heart baby, an...\n",
       "25296      1  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...\n",
       "\n",
       "[4163 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech2 = speech2.loc[:,['tweet', 'class']] \n",
    "# Séparer les classes 'Hate', 'Offensive', 'Neutral' en 2 classes binaires : offensif ou neutre\n",
    "speech2['good_bad'] = speech2['class'].apply(lambda x : 0 if x == 0 or x == 1\n",
    "                                                        else 1)\n",
    "speech2.dropna(axis = 0)\n",
    "speech2 = speech2[speech2['good_bad'] == 1] #On ne gardera que les ligne où les tweets sont considérés offensifs.\n",
    "speech2.drop(columns = 'class', inplace = True)\n",
    "speech2 = speech2[speech2.columns[::-1]] #Changer l'ordre des colones afin de concatener les deux dataframes\n",
    "speech2.rename(columns = {'good_bad' : 'label'}, inplace = True)\n",
    "speech2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d91306a3",
   "metadata": {
    "id": "00cc4d79-c31c-432e-bf8e-f37b2acd37b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     6405\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech3 = pd.concat([speech1,speech2], axis=0)\n",
    "speech3['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "869357dc",
   "metadata": {
    "id": "a77c3c3a-2323-483d-b42d-4bfb40a43f89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22932</th>\n",
       "      <td>0</td>\n",
       "      <td>how the @user made grandma sad. #grandma,   #l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10886</th>\n",
       "      <td>0</td>\n",
       "      <td>i am independent. #i_am #positive #affirmation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15443</th>\n",
       "      <td>0</td>\n",
       "      <td>enjoy #lifeofaking starring cuba gooding jr ! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15569</th>\n",
       "      <td>0</td>\n",
       "      <td>going to #fabcon3d tomorrow! talk scheduled fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26575</th>\n",
       "      <td>0</td>\n",
       "      <td>@user went to fye and they didn't have your al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21724</th>\n",
       "      <td>0</td>\n",
       "      <td>@user   take a look. #ukip in scotland are non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31829</th>\n",
       "      <td>0</td>\n",
       "      <td>happy daddy's day to all the fab dads out ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28635</th>\n",
       "      <td>0</td>\n",
       "      <td>a girl broken his hea ð ð ââââ #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11916</th>\n",
       "      <td>0</td>\n",
       "      <td>update: my free app will be live within 7 days.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28328</th>\n",
       "      <td>0</td>\n",
       "      <td>#juneteenth, our #annual #celebration of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6405 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "22932      0  how the @user made grandma sad. #grandma,   #l...\n",
       "10886      0  i am independent. #i_am #positive #affirmation...\n",
       "15443      0  enjoy #lifeofaking starring cuba gooding jr ! ...\n",
       "15569      0  going to #fabcon3d tomorrow! talk scheduled fo...\n",
       "26575      0  @user went to fye and they didn't have your al...\n",
       "...      ...                                                ...\n",
       "21724      0  @user   take a look. #ukip in scotland are non...\n",
       "31829      0  happy daddy's day to all the fab dads out ther...\n",
       "28635      0  a girl broken his hea ð ð ââââ #...\n",
       "11916      0  update: my free app will be live within 7 days.  \n",
       "28328      0    #juneteenth, our #annual #celebration of the...\n",
       "\n",
       "[6405 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Créer un dataframe équilibré.\n",
    "speech3[speech3['label'] == 1 ]\n",
    "speech3[speech3['label'] == 0 ].sample(speech3[speech3['label'] == 1 ].count()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43b8ce80",
   "metadata": {
    "id": "7348d4d3-0692-4234-a3cf-1232bd7d191a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>#newyearseve #skynews presenter to asian woman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@LILNTHEBASEDGOD her face ugly to me, &amp;amp; he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>oh how disappointed i was to see that there wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>\"the dying of the light\"  village green/townÂ²...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@BlackManUSA @chrislhayes well that's some cra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12805</th>\n",
       "      <td>0</td>\n",
       "      <td>@user i have missed radio next week back in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12806</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @WorIdStarFunnyy: this the \"I play soccer, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12807</th>\n",
       "      <td>0</td>\n",
       "      <td>kim taeyeon!  @user new project coming up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12808</th>\n",
       "      <td>1</td>\n",
       "      <td>\"@BabyAnimalPics: baby monkey bathtime http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12809</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @calvin2000: Really? This is what's concern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12810 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "0          1  #newyearseve #skynews presenter to asian woman...\n",
       "1          1  @LILNTHEBASEDGOD her face ugly to me, &amp; he...\n",
       "2          0  oh how disappointed i was to see that there wa...\n",
       "3          1  \"the dying of the light\"  village green/townÂ²...\n",
       "4          1  @BlackManUSA @chrislhayes well that's some cra...\n",
       "...      ...                                                ...\n",
       "12805      0   @user i have missed radio next week back in t...\n",
       "12806      1  RT @WorIdStarFunnyy: this the \"I play soccer, ...\n",
       "12807      0       kim taeyeon!  @user new project coming up.  \n",
       "12808      1  \"@BabyAnimalPics: baby monkey bathtime http://...\n",
       "12809      1  RT @calvin2000: Really? This is what's concern...\n",
       "\n",
       "[12810 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech = pd.concat([\n",
    "                    speech3[speech3['label'] == 1] ,\n",
    "                    speech3[speech3['label'] == 0].sample(speech3[speech3['label'] == 1 ].count()[0]\n",
    "                    )],\n",
    "                    axis = 0 )\n",
    "\n",
    "speech = speech.sample(frac=1) #Shuffling du dataset\n",
    "speech = speech.reset_index() #Resetting index\n",
    "speech= speech.drop('index', axis = 1)\n",
    "\n",
    "#aligner les noms de colonnes\n",
    "\n",
    "speech.rename(columns = {'tweet' : 'text'}, inplace = True)\n",
    "speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f613ce8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1637179872518,
     "user": {
      "displayName": "Youss BBB",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04616849028342739253"
     },
     "user_tz": -60
    },
    "id": "04c229be-b8c3-4a18-88a5-bb2d30ed1853",
    "outputId": "eaf67c20-2b4c-4ab7-884c-2f37d31e7ea0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>#newyearseve #skynews presenter to asian woman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@LILNTHEBASEDGOD her face ugly to me, &amp;amp; he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>oh how disappointed i was to see that there wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>\"the dying of the light\"  village green/townÂ²...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@BlackManUSA @chrislhayes well that's some cra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  #newyearseve #skynews presenter to asian woman...\n",
       "1      1  @LILNTHEBASEDGOD her face ugly to me, &amp; he...\n",
       "2      0  oh how disappointed i was to see that there wa...\n",
       "3      1  \"the dying of the light\"  village green/townÂ²...\n",
       "4      1  @BlackManUSA @chrislhayes well that's some cra..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "841e99b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6405\n",
       "0    6405\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc7de4a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1637179872521,
     "user": {
      "displayName": "Youss BBB",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04616849028342739253"
     },
     "user_tz": -60
    },
    "id": "06889f95-3f32-4a5c-8bf1-dbf56ce3da04",
    "outputId": "8ec54254-b272-460f-ba68-d44c8783a0a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12810 entries, 0 to 12809\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   12810 non-null  int64 \n",
      " 1   text    12810 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 200.3+ KB\n"
     ]
    }
   ],
   "source": [
    "speech.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1069fe8d",
   "metadata": {
    "id": "0814bba7-7d09-462b-b12e-7ff2a8888ed7"
   },
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3b3a60",
   "metadata": {
    "id": "91a18313-5591-4bd0-bb50-3ccb75cb5482"
   },
   "source": [
    "### Preprocessing texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd152216",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7191,
     "status": "ok",
     "timestamp": 1637229544799,
     "user": {
      "displayName": "Youss BBB",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04616849028342739253"
     },
     "user_tz": -60
    },
    "id": "TAeJIzW8OVmc",
    "outputId": "09b35c52-4072-4138-b241-e8b278c294ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download(\"en_core_web_md\")\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0b3da81",
   "metadata": {
    "id": "8989912f-fc28-4363-97e2-720986089762"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0632e6cc-e07f-43e6-8408-62b95574720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490\n",
    "def decontracted(phrase):\n",
    "    \"\"\"Convert contractions like \"can't\" into \"can not\"\n",
    "    \"\"\"\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    #phrase = re.sub(r\"n't\", \" not\", phrase) # resulted in \"ca not\" when sentence started with \"can't\"\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "\n",
    "slang_abbrev_dict = {\n",
    "    'AFAIK': 'As Far As I Know',\n",
    "    'AFK': 'Away From Keyboard',\n",
    "    'ASAP': 'As Soon As Possible',\n",
    "    'ATK': 'At The Keyboard',\n",
    "    'ATM': 'At The Moment',\n",
    "    'A3': 'Anytime, Anywhere, Anyplace',\n",
    "    'BAK': 'Back At Keyboard',\n",
    "    'BBL': 'Be Back Later',\n",
    "    'BBS': 'Be Back Soon',\n",
    "    'BFN': 'Bye For Now',\n",
    "    'B4N': 'Bye For Now',\n",
    "    'BRB': 'Be Right Back',\n",
    "    'BRT': 'Be Right There',\n",
    "    'BTW': 'By The Way',\n",
    "    'B4': 'Before',\n",
    "    'B4N': 'Bye For Now',\n",
    "    'CU': 'See You',\n",
    "    'CUL8R': 'See You Later',\n",
    "    'CYA': 'See You',\n",
    "    'FAQ': 'Frequently Asked Questions',\n",
    "    'FC': 'Fingers Crossed',\n",
    "    'FWIW': 'For What It\\'s Worth',\n",
    "    'FYI': 'For Your Information',\n",
    "    'GAL': 'Get A Life',\n",
    "    'GG': 'Good Game',\n",
    "    'GN': 'Good Night',\n",
    "    'GMTA': 'Great Minds Think Alike',\n",
    "    'GR8': 'Great!',\n",
    "    'G9': 'Genius',\n",
    "    'IC': 'I See',\n",
    "    'ICQ': 'I Seek you',\n",
    "    'ILU': 'I Love You',\n",
    "    'IMHO': 'In My Humble Opinion',\n",
    "    'IMO': 'In My Opinion',\n",
    "    'IOW': 'In Other Words',\n",
    "    'IRL': 'In Real Life',\n",
    "    'KISS': 'Keep It Simple, Stupid',\n",
    "    'LDR': 'Long Distance Relationship',\n",
    "    'LMAO': 'Laugh My Ass Off',\n",
    "    'LOL': 'Laughing Out Loud',\n",
    "    'LTNS': 'Long Time No See',\n",
    "    'L8R': 'Later',\n",
    "    'MTE': 'My Thoughts Exactly',\n",
    "    'M8': 'Mate',\n",
    "    'NRN': 'No Reply Necessary',\n",
    "    'OIC': 'Oh I See',\n",
    "    'OMG': 'Oh My God',\n",
    "    'PITA': 'Pain In The Ass',\n",
    "    'PRT': 'Party',\n",
    "    'PRW': 'Parents Are Watching',\n",
    "    'QPSA?': 'Que Pasa?',\n",
    "    'ROFL': 'Rolling On The Floor Laughing',\n",
    "    'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
    "    'ROTFLMAO': 'Rolling On The Floor Laughing My Ass Off',\n",
    "    'SK8': 'Skate',\n",
    "    'STATS': 'Your sex and age',\n",
    "    'ASL': 'Age, Sex, Location',\n",
    "    'THX': 'Thank You',\n",
    "    'TTFN': 'Ta-Ta For Now!',\n",
    "    'TTYL': 'Talk To You Later',\n",
    "    'U': 'You',\n",
    "    'U2': 'You Too',\n",
    "    'U4E': 'Yours For Ever',\n",
    "    'WB': 'Welcome Back',\n",
    "    'WTF': 'What The Fuck',\n",
    "    'WTG': 'Way To Go!',\n",
    "    'WUF': 'Where Are You From?',\n",
    "    'W8': 'Wait',\n",
    "    '7K': 'Sick:-D Laugher'\n",
    "}\n",
    "\n",
    "\n",
    "def unslang(text):\n",
    "    \"\"\"Converts text like \"OMG\" into \"Oh my God\"\n",
    "    \"\"\"\n",
    "    if text.upper() in slang_abbrev_dict.keys():\n",
    "        return slang_abbrev_dict[text.upper()]\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "\n",
    "stopwords = [\n",
    "    \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"ain\", \"all\", \"am\",\n",
    "    \"an\", \"and\", \"any\", \"are\", \"aren\", \"aren't\", \"as\", \"at\", \"be\", \"because\",\n",
    "    \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can\",\n",
    "    \"couldn\", \"couldn't\", \"d\", \"did\", \"didn\", \"didn't\", \"do\", \"does\", \"doesn\",\n",
    "    \"doesn't\", \"doing\", \"don\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\",\n",
    "    \"from\", \"further\", \"had\", \"hadn\", \"hadn't\", \"has\", \"hasn\", \"hasn't\", \"have\",\n",
    "    \"haven\", \"haven't\", \"having\", \"he\", \"her\", \"here\", \"hers\", \"herself\", \"him\",\n",
    "    \"himself\", \"his\", \"how\", \"i\", \"if\", \"in\", \"into\", \"is\", \"isn\", \"isn't\",\n",
    "    \"it\", \"it's\", \"its\", \"itself\", \"just\", \"ll\", \"m\", \"ma\", \"me\", \"mightn\",\n",
    "    \"mightn't\", \"more\", \"most\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"needn\",\n",
    "    \"needn't\", \"no\", \"nor\", \"not\", \"now\", \"o\", \"of\", \"off\", \"on\", \"once\",\n",
    "    \"only\", \"or\", \"other\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\",\n",
    "    \"re\", \"s\", \"same\", \"shan\", \"shan't\", \"she\", \"she's\", \"should\", \"should've\",\n",
    "    \"shouldn\", \"shouldn't\", \"so\", \"some\", \"such\", \"t\", \"than\", \"that\",\n",
    "    \"that'll\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\",\n",
    "    \"these\", \"they\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\",\n",
    "    \"up\", \"ve\", \"very\", \"was\", \"wasn\", \"wasn't\", \"we\", \"were\", \"weren\",\n",
    "    \"weren't\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\",\n",
    "    \"will\", \"with\", \"won\", \"won't\", \"wouldn\", \"wouldn't\", \"y\", \"you\", \"you'd\",\n",
    "    \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
    "    \"could\", \"he'd\", \"he'll\", \"he's\", \"here's\", \"how's\", \"i'd\", \"i'll\", \"i'm\",\n",
    "    \"i've\", \"let's\", \"ought\", \"she'd\", \"she'll\", \"that's\", \"there's\", \"they'd\",\n",
    "    \"they'll\", \"they're\", \"they've\", \"we'd\", \"we'll\", \"we're\", \"we've\",\n",
    "    \"what's\", \"when's\", \"where's\", \"who's\", \"why's\", \"would\", \"able\", \"abst\",\n",
    "    \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\",\n",
    "    \"added\", \"adj\", \"affected\", \"affecting\", \"affects\", \"afterwards\", \"ah\",\n",
    "    \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"among\", \"amongst\", \"announce\", \"another\", \"anybody\", \"anyhow\", \"anymore\",\n",
    "    \"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"apparently\",\n",
    "    \"approximately\", \"arent\", \"arise\", \"around\", \"aside\", \"ask\", \"asking\",\n",
    "    \"auth\", \"available\", \"away\", \"awfully\", \"b\", \"back\", \"became\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"beforehand\", \"begin\", \"beginning\", \"beginnings\",\n",
    "    \"begins\", \"behind\", \"believe\", \"beside\", \"besides\", \"beyond\", \"biol\",\n",
    "    \"brief\", \"briefly\", \"c\", \"ca\", \"came\", \"cannot\", \"can't\", \"cause\", \"causes\",\n",
    "    \"certain\", \"certainly\", \"co\", \"com\", \"come\", \"comes\", \"contain\",\n",
    "    \"containing\", \"contains\", \"couldnt\", \"date\", \"different\", \"done\",\n",
    "    \"downwards\", \"due\", \"e\", \"ed\", \"edu\", \"effect\", \"eg\", \"eight\", \"eighty\",\n",
    "    \"either\", \"else\", \"elsewhere\", \"end\", \"ending\", \"enough\", \"especially\",\n",
    "    \"et\", \"etc\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\",\n",
    "    \"everywhere\", \"ex\", \"except\", \"f\", \"far\", \"ff\", \"fifth\", \"first\", \"five\",\n",
    "    \"fix\", \"followed\", \"following\", \"follows\", \"former\", \"formerly\", \"forth\",\n",
    "    \"found\", \"four\", \"furthermore\", \"g\", \"gave\", \"get\", \"gets\", \"getting\",\n",
    "    \"give\", \"given\", \"gives\", \"giving\", \"go\", \"goes\", \"gone\", \"got\", \"gotten\",\n",
    "    \"h\", \"happens\", \"hardly\", \"hed\", \"hence\", \"hereafter\", \"hereby\", \"herein\",\n",
    "    \"heres\", \"hereupon\", \"hes\", \"hi\", \"hid\", \"hither\", \"home\", \"howbeit\",\n",
    "    \"however\", \"hundred\", \"id\", \"ie\", \"im\", \"immediate\", \"immediately\",\n",
    "    \"importance\", \"important\", \"inc\", \"indeed\", \"index\", \"information\",\n",
    "    \"instead\", \"invention\", \"inward\", \"itd\", \"it'll\", \"j\", \"k\", \"keep\", \"keeps\",\n",
    "    \"kept\", \"kg\", \"km\", \"know\", \"known\", \"knows\", \"l\", \"largely\", \"last\",\n",
    "    \"lately\", \"later\", \"latter\", \"latterly\", \"least\", \"less\", \"lest\", \"let\",\n",
    "    \"lets\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"'ll\", \"look\",\n",
    "    \"looking\", \"looks\", \"ltd\", \"made\", \"mainly\", \"make\", \"makes\", \"many\", \"may\",\n",
    "    \"maybe\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"might\",\n",
    "    \"million\", \"miss\", \"ml\", \"moreover\", \"mostly\", \"mr\", \"mrs\", \"much\", \"mug\",\n",
    "    \"must\", \"n\", \"na\", \"name\", \"namely\", \"nay\", \"nd\", \"near\", \"nearly\",\n",
    "    \"necessarily\", \"necessary\", \"need\", \"needs\", \"neither\", \"never\",\n",
    "    \"nevertheless\", \"new\", \"next\", \"nine\", \"ninety\", \"nobody\", \"non\", \"none\",\n",
    "    \"nonetheless\", \"noone\", \"normally\", \"nos\", \"noted\", \"nothing\", \"nowhere\",\n",
    "    \"obtain\", \"obtained\", \"obviously\", \"often\", \"oh\", \"ok\", \"okay\", \"old\",\n",
    "    \"omitted\", \"one\", \"ones\", \"onto\", \"ord\", \"others\", \"otherwise\", \"outside\",\n",
    "    \"overall\", \"owing\", \"p\", \"page\", \"pages\", \"part\", \"particular\",\n",
    "    \"particularly\", \"past\", \"per\", \"perhaps\", \"placed\", \"please\", \"plus\",\n",
    "    \"poorly\", \"possible\", \"possibly\", \"potentially\", \"pp\", \"predominantly\",\n",
    "    \"present\", \"previously\", \"primarily\", \"probably\", \"promptly\", \"proud\",\n",
    "    \"provides\", \"put\", \"q\", \"que\", \"quickly\", \"quite\", \"qv\", \"r\", \"ran\",\n",
    "    \"rather\", \"rd\", \"readily\", \"really\", \"recent\", \"recently\", \"ref\", \"refs\",\n",
    "    \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research\",\n",
    "    \"respectively\", \"resulted\", \"resulting\", \"results\", \"right\", \"run\", \"said\",\n",
    "    \"saw\", \"say\", \"saying\", \"says\", \"sec\", \"section\", \"see\", \"seeing\", \"seem\",\n",
    "    \"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sent\", \"seven\",\n",
    "    \"several\", \"shall\", \"shed\", \"shes\", \"show\", \"showed\", \"shown\", \"showns\",\n",
    "    \"shows\", \"significant\", \"significantly\", \"similar\", \"similarly\", \"since\",\n",
    "    \"six\", \"slightly\", \"somebody\", \"somehow\", \"someone\", \"somethan\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\",\n",
    "    \"sorry\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"still\",\n",
    "    \"stop\", \"strongly\", \"sub\", \"substantially\", \"successfully\", \"sufficiently\",\n",
    "    \"suggest\", \"sup\", \"sure\", \"take\", \"taken\", \"taking\", \"tell\", \"tends\", \"th\",\n",
    "    \"thank\", \"thanks\", \"thanx\", \"thats\", \"that've\", \"thence\", \"thereafter\",\n",
    "    \"thereby\", \"thered\", \"therefore\", \"therein\", \"there'll\", \"thereof\",\n",
    "    \"therere\", \"theres\", \"thereto\", \"thereupon\", \"there've\", \"theyd\", \"theyre\",\n",
    "    \"think\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"throug\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"til\", \"tip\", \"together\", \"took\", \"toward\", \"towards\",\n",
    "    \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"twice\", \"two\", \"u\", \"un\",\n",
    "    \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"unto\", \"upon\", \"ups\",\n",
    "    \"us\", \"use\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"uses\", \"using\",\n",
    "    \"usually\", \"v\", \"value\", \"various\", \"'ve\", \"via\", \"viz\", \"vol\", \"vols\",\n",
    "    \"vs\", \"w\", \"want\", \"wants\", \"wasnt\", \"way\", \"wed\", \"welcome\", \"went\",\n",
    "    \"werent\", \"whatever\", \"what'll\", \"whats\", \"whence\", \"whenever\",\n",
    "    \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"whereupon\",\n",
    "    \"wherever\", \"whether\", \"whim\", \"whither\", \"whod\", \"whoever\", \"whole\",\n",
    "    \"who'll\", \"whomever\", \"whos\", \"whose\", \"widely\", \"willing\", \"wish\",\n",
    "    \"within\", \"without\", \"wont\", \"words\", \"world\", \"wouldnt\", \"www\", \"x\", \"yes\",\n",
    "    \"yet\", \"youd\", \"youre\", \"z\", \"zero\", \"a's\", \"ain't\", \"allow\", \"allows\",\n",
    "    \"apart\", \"appear\", \"appreciate\", \"appropriate\", \"associated\", \"best\",\n",
    "    \"better\", \"c'mon\", \"c's\", \"cant\", \"changes\", \"clearly\", \"concerning\",\n",
    "    \"consequently\", \"consider\", \"considering\", \"corresponding\", \"course\",\n",
    "    \"currently\", \"definitely\", \"described\", \"despite\", \"entirely\", \"exactly\",\n",
    "    \"example\", \"going\", \"greetings\", \"hello\", \"help\", \"hopefully\", \"ignored\",\n",
    "    \"inasmuch\", \"indicate\", \"indicated\", \"indicates\", \"inner\", \"insofar\",\n",
    "    \"it'd\", \"keep\", \"keeps\", \"novel\", \"presumably\", \"reasonably\", \"second\",\n",
    "    \"secondly\", \"sensible\", \"serious\", \"seriously\", \"sure\", \"t's\", \"third\",\n",
    "    \"thorough\", \"thoroughly\", \"three\", \"well\", \"wonder\", \"a\", \"about\", \"above\",\n",
    "    \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\",\n",
    "    \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\",\n",
    "    \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\", \"any\",\n",
    "    \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\", \"around\", \"as\",\n",
    "    \"at\", \"back\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\",\n",
    "    \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\",\n",
    "    \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\", \"but\", \"by\",\n",
    "    \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\",\n",
    "    \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\",\n",
    "    \"eg\", \"eight\", \"either\", \"eleven\", \"else\", \"elsewhere\", \"empty\", \"enough\",\n",
    "    \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\",\n",
    "    \"except\", \"few\", \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\",\n",
    "    \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\",\n",
    "    \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\",\n",
    "    \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\",\n",
    "    \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \"if\",\n",
    "    \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\",\n",
    "    \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\",\n",
    "    \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\",\n",
    "    \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\",\n",
    "    \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\",\n",
    "    \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\",\n",
    "    \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\",\n",
    "    \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\",\n",
    "    \"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\",\n",
    "    \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\",\n",
    "    \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\",\n",
    "    \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\",\n",
    "    \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thickv\", \"thin\",\n",
    "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\",\n",
    "    \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
    "    \"the\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\",\n",
    "    \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"A\", \"B\", \"C\",\n",
    "    \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\",\n",
    "    \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"co\", \"op\", \"research-articl\",\n",
    "    \"pagecount\", \"cit\", \"ibid\", \"les\", \"le\", \"au\", \"que\", \"est\", \"pas\", \"vol\",\n",
    "    \"el\", \"los\", \"pp\", \"u201d\", \"well-b\", \"http\", \"volumtype\", \"par\", \"0o\",\n",
    "    \"0s\", \"3a\", \"3b\", \"3d\", \"6b\", \"6o\", \"a1\", \"a2\", \"a3\", \"a4\", \"ab\", \"ac\",\n",
    "    \"ad\", \"ae\", \"af\", \"ag\", \"aj\", \"al\", \"an\", \"ao\", \"ap\", \"ar\", \"av\", \"aw\",\n",
    "    \"ax\", \"ay\", \"az\", \"b1\", \"b2\", \"b3\", \"ba\", \"bc\", \"bd\", \"be\", \"bi\", \"bj\",\n",
    "    \"bk\", \"bl\", \"bn\", \"bp\", \"br\", \"bs\", \"bt\", \"bu\", \"bx\", \"c1\", \"c2\", \"c3\",\n",
    "    \"cc\", \"cd\", \"ce\", \"cf\", \"cg\", \"ch\", \"ci\", \"cj\", \"cl\", \"cm\", \"cn\", \"cp\",\n",
    "    \"cq\", \"cr\", \"cs\", \"ct\", \"cu\", \"cv\", \"cx\", \"cy\", \"cz\", \"d2\", \"da\", \"dc\",\n",
    "    \"dd\", \"de\", \"df\", \"di\", \"dj\", \"dk\", \"dl\", \"do\", \"dp\", \"dr\", \"ds\", \"dt\",\n",
    "    \"du\", \"dx\", \"dy\", \"e2\", \"e3\", \"ea\", \"ec\", \"ed\", \"ee\", \"ef\", \"ei\", \"ej\",\n",
    "    \"el\", \"em\", \"en\", \"eo\", \"ep\", \"eq\", \"er\", \"es\", \"et\", \"eu\", \"ev\", \"ex\",\n",
    "    \"ey\", \"f2\", \"fa\", \"fc\", \"ff\", \"fi\", \"fj\", \"fl\", \"fn\", \"fo\", \"fr\", \"fs\",\n",
    "    \"ft\", \"fu\", \"fy\", \"ga\", \"ge\", \"gi\", \"gj\", \"gl\", \"go\", \"gr\", \"gs\", \"gy\",\n",
    "    \"h2\", \"h3\", \"hh\", \"hi\", \"hj\", \"ho\", \"hr\", \"hs\", \"hu\", \"hy\", \"i\", \"i2\", \"i3\",\n",
    "    \"i4\", \"i6\", \"i7\", \"i8\", \"ia\", \"ib\", \"ic\", \"ie\", \"ig\", \"ih\", \"ii\", \"ij\",\n",
    "    \"il\", \"in\", \"io\", \"ip\", \"iq\", \"ir\", \"iv\", \"ix\", \"iy\", \"iz\", \"jj\", \"jr\",\n",
    "    \"js\", \"jt\", \"ju\", \"ke\", \"kg\", \"kj\", \"km\", \"ko\", \"l2\", \"la\", \"lb\", \"lc\",\n",
    "    \"lf\", \"lj\", \"ln\", \"lo\", \"lr\", \"ls\", \"lt\", \"m2\", \"ml\", \"mn\", \"mo\", \"ms\",\n",
    "    \"mt\", \"mu\", \"n2\", \"nc\", \"nd\", \"ne\", \"ng\", \"ni\", \"nj\", \"nl\", \"nn\", \"nr\",\n",
    "    \"ns\", \"nt\", \"ny\", \"oa\", \"ob\", \"oc\", \"od\", \"of\", \"og\", \"oi\", \"oj\", \"ol\",\n",
    "    \"om\", \"on\", \"oo\", \"oq\", \"or\", \"os\", \"ot\", \"ou\", \"ow\", \"ox\", \"oz\", \"p1\",\n",
    "    \"p2\", \"p3\", \"pc\", \"pd\", \"pe\", \"pf\", \"ph\", \"pi\", \"pj\", \"pk\", \"pl\", \"pm\",\n",
    "    \"pn\", \"po\", \"pq\", \"pr\", \"ps\", \"pt\", \"pu\", \"py\", \"qj\", \"qu\", \"r2\", \"ra\",\n",
    "    \"rc\", \"rd\", \"rf\", \"rh\", \"ri\", \"rj\", \"rl\", \"rm\", \"rn\", \"ro\", \"rq\", \"rr\",\n",
    "    \"rs\", \"rt\", \"ru\", \"rv\", \"ry\", \"s2\", \"sa\", \"sc\", \"sd\", \"se\", \"sf\", \"si\",\n",
    "    \"sj\", \"sl\", \"sm\", \"sn\", \"sp\", \"sq\", \"sr\", \"ss\", \"st\", \"sy\", \"sz\", \"t1\",\n",
    "    \"t2\", \"t3\", \"tb\", \"tc\", \"td\", \"te\", \"tf\", \"th\", \"ti\", \"tj\", \"tl\", \"tm\",\n",
    "    \"tn\", \"tp\", \"tq\", \"tr\", \"ts\", \"tt\", \"tv\", \"tx\", \"ue\", \"ui\", \"uj\", \"uk\",\n",
    "    \"um\", \"un\", \"uo\", \"ur\", \"ut\", \"va\", \"wa\", \"vd\", \"wi\", \"vj\", \"vo\", \"wo\",\n",
    "    \"vq\", \"vt\", \"vu\", \"x1\", \"x2\", \"x3\", \"xf\", \"xi\", \"xj\", \"xk\", \"xl\", \"xn\",\n",
    "    \"xo\", \"xs\", \"xt\", \"xv\", \"xx\", \"y2\", \"yj\", \"yl\", \"yr\", \"ys\", \"yt\", \"zi\", \"zz\"\n",
    "]\n",
    "\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "# from: https://www.kaggle.com/shahules/basic-eda-cleaning-and-glove\n",
    "# maybe a bug, it removes question marks?\n",
    "spell = SpellChecker()\n",
    "\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "def remove_urls(text):\n",
    "    text = clean(r\"http\\S+\", text)\n",
    "    text = clean(r\"www\\S+\", text)\n",
    "    text = clean(r\"pic.twitter.com\\S+\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def clean(reg_exp, text):\n",
    "    text = re.sub(reg_exp, \" \", text)\n",
    "\n",
    "    # replace multiple spaces with one.\n",
    "    text = re.sub('\\s{2,}', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_all(t, correct_spelling=False, remove_stopwords=False, lemmatize=False):\n",
    "    \n",
    "    # first do bulk cleanup on tokens that don't depend on word tokenization\n",
    "\n",
    "    t = re.sub('rt', '', t) #'Retweets'\n",
    "    \n",
    "    t = re.sub('[0-9]', '', t) #chiffre\n",
    "    \n",
    "    #Usernames\n",
    "    t = re.sub( r'(^|[^@\\w])@(\\w{1,15})\\b', '',t) #Twitter Usernames \n",
    "    \n",
    "    # remove xml tags\n",
    "    t = clean(r\"<[^>]+>\", t)\n",
    "    t = clean(r\"&lt;\", t)\n",
    "    t = clean(r\"&gt;\", t)\n",
    "\n",
    "    # remove URLs\n",
    "    t = remove_urls(t)\n",
    "\n",
    "    # https://stackoverflow.com/a/35041925\n",
    "    # replace multiple punctuation with single. Ex: !?!?!? would become ?\n",
    "    t = clean(r'[\\?\\.\\!]+(?=[\\?\\.\\!])', t)\n",
    "\n",
    "    t = remove_emoji(t)\n",
    "\n",
    "    # expand common contractions like \"I'm\" \"he'll\"\n",
    "    t = decontracted(t)\n",
    "\n",
    "    # now remove/expand bad patterns per word\n",
    "    words = word_tokenize(t)\n",
    "\n",
    "    # remove stopwords\n",
    "    if remove_stopwords is True:\n",
    "        words = [w for w in words if not w in stopwords]\n",
    "\n",
    "    clean_words = []\n",
    "\n",
    "    for w in words:\n",
    "        # normalize punctuation\n",
    "        w = re.sub(r'&', 'and', w)\n",
    "\n",
    "        # expand slang like OMG = Oh my God\n",
    "        w = unslang(w)\n",
    "\n",
    "        if lemmatize is True:\n",
    "            w = lemmatizer.lemmatize(w)\n",
    "        \n",
    "        clean_words.append(w)\n",
    "\n",
    "        # join the words back into a full string\n",
    "        #t = untokenize(clean_words)\n",
    "\n",
    "    if correct_spelling is True:\n",
    "        # this resulted in lots of lost punctuation - omitting for now. Also greatly speeds things up\n",
    "        t = correct_spellings(t)\n",
    "\n",
    "    # finally, remove any non ascii and special characters that made it through\n",
    "    t = clean(r\"[^A-Za-z0-9\\.\\'!\\?,\\$]\", t)\n",
    "    \n",
    "    #Removing punctuation and lower\n",
    "    t = re.sub('[#$%&?,!()*+-/:;<=>@]', '', t).lower()\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "def clean_dataframe(df, correct_spelling=False, remove_stopwords=False):\n",
    "    df['clean'] = df.apply(lambda x: clean_all(x['text'], correct_spelling=correct_spelling, remove_stopwords=remove_stopwords), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def parallelize_dataframe(\n",
    "        df, func, n_cores=2):  # I think Kaggle notebooks only have 2 cores?\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df9a09b8-350b-4da3-a250-62e000a1aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning process\n",
    "speech['clean_text'] = speech['text'].apply(lambda x: clean_all(x, \n",
    "                                                                correct_spelling=True, \n",
    "                                                                remove_stopwords=True, \n",
    "                                                                lemmatize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ba17f13-2e3e-4e58-aa15-51a31433d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the clean dataframe to save time\n",
    "speech.to_csv('speech_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ff20ec9-d934-4904-8917-51f1e93eeb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemma\n",
    "def lemmatize(text):\n",
    "    text = nlp(text)\n",
    "    text = text = ' '.join([token.lemma_ for token in text if token.lemma not in STOP_WORDS and token.text not in STOP_WORDS])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fd74723",
   "metadata": {
    "id": "231012c3-2f96-432c-a741-5abac689d475"
   },
   "outputs": [],
   "source": [
    "speech['clean_lemma'] = speech['clean_text'].apply(lambda x : lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b184ef5c-5ebe-48fc-b57e-f8dd156543fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          newyearseve skynews presenter asian woman ed...\n",
       "1                                face ugly camp nude trash\n",
       "2        oh disappointed reddeadredemption sequel announce\n",
       "3        dying light village green town antisemitism ho...\n",
       "4                     cracker jack secret service work jak\n",
       "                               ...                        \n",
       "12805    miss radio week game cover show come   radioli...\n",
       "12806    rt play soccer cheat girl wear khaki colour ca...\n",
       "12807                         kim taeyeon new project come\n",
       "12808                  baby monkey bathtime soooo adorable\n",
       "12809    rt concern right mt look ford speak john kerry...\n",
       "Name: clean_lemma, Length: 12810, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech['clean_lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eddf8ca3",
   "metadata": {
    "id": "223a87ce-dd61-43b7-848b-edf46631cb80"
   },
   "outputs": [],
   "source": [
    "#Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c07687d",
   "metadata": {
    "id": "5d79e179-63e3-4a9c-9253-f9271a9dd1d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_lemma</th>\n",
       "      <th>tokens_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>#newyearseve #skynews presenter to asian woman...</td>\n",
       "      <td>newyearseve skynews presenter to asian woman ...</td>\n",
       "      <td>newyearseve skynews presenter asian woman ed...</td>\n",
       "      <td>[3024, 7153, 4866, 272, 44, 2583, 197, 272, 44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@LILNTHEBASEDGOD her face ugly to me, &amp;amp; he...</td>\n",
       "      <td>her face ugly to me camp her nudes were trash</td>\n",
       "      <td>face ugly camp nude trash</td>\n",
       "      <td>[171, 804, 4, 468, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>oh how disappointed i was to see that there wa...</td>\n",
       "      <td>oh how disappointed i was to see that there wa...</td>\n",
       "      <td>oh disappointed reddeadredemption sequel announce</td>\n",
       "      <td>[163, 1193, 7154, 3709, 761]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>\"the dying of the light\"  village green/townÂ²...</td>\n",
       "      <td>the dying of the light village green town anti...</td>\n",
       "      <td>dying light village green town antisemitism ho...</td>\n",
       "      <td>[4867, 225, 2584, 298, 653, 1194, 4868, 4869, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@BlackManUSA @chrislhayes well that's some cra...</td>\n",
       "      <td>well that is some cracker jack secret service ...</td>\n",
       "      <td>cracker jack secret service work jak</td>\n",
       "      <td>[209, 2012, 851, 672, 27, 7155]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0      1  #newyearseve #skynews presenter to asian woman...   \n",
       "1      1  @LILNTHEBASEDGOD her face ugly to me, &amp; he...   \n",
       "2      0  oh how disappointed i was to see that there wa...   \n",
       "3      1  \"the dying of the light\"  village green/townÂ²...   \n",
       "4      1  @BlackManUSA @chrislhayes well that's some cra...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0   newyearseve skynews presenter to asian woman ...   \n",
       "1      her face ugly to me camp her nudes were trash   \n",
       "2  oh how disappointed i was to see that there wa...   \n",
       "3  the dying of the light village green town anti...   \n",
       "4  well that is some cracker jack secret service ...   \n",
       "\n",
       "                                         clean_lemma  \\\n",
       "0    newyearseve skynews presenter asian woman ed...   \n",
       "1                          face ugly camp nude trash   \n",
       "2  oh disappointed reddeadredemption sequel announce   \n",
       "3  dying light village green town antisemitism ho...   \n",
       "4               cracker jack secret service work jak   \n",
       "\n",
       "                                    tokens_sequences  \n",
       "0  [3024, 7153, 4866, 272, 44, 2583, 197, 272, 44...  \n",
       "1                              [171, 804, 4, 468, 5]  \n",
       "2                       [163, 1193, 7154, 3709, 761]  \n",
       "3  [4867, 225, 2584, 298, 653, 1194, 4868, 4869, ...  \n",
       "4                    [209, 2012, 851, 672, 27, 7155]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transformation des textes en tokens, sequences puis sequences padded\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer() # Tokenizer instance\n",
    "tokenizer.fit_on_texts(speech['clean_lemma']) #Lemme to Tokens\n",
    "speech['tokens_sequences'] = tokenizer.texts_to_sequences(speech['clean_lemma']) #Tokens to sequences \n",
    "speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f0f83b0",
   "metadata": {
    "id": "44e75167-73e6-4a98-98d0-286c85e79fba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3024,  7153,  4866, ...,     0,     0,     0],\n",
       "       [  171,   804,     4, ...,     0,     0,     0],\n",
       "       [  163,  1193,  7154, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [ 1966, 17652,    13, ...,     0,     0,     0],\n",
       "       [  116,    86, 17653, ...,     0,     0,     0],\n",
       "       [    1,  2857,    39, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Padding des sequences.\n",
    "tweets_padded = tf.keras.preprocessing.sequence.pad_sequences(speech.tokens_sequences, padding=\"post\")\n",
    "tweets_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ebd7840",
   "metadata": {
    "id": "44a8eb95-1c8f-4b0c-a057-4d89da5f7c7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((31,), ()), types: (tf.int32, tf.int64)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the tensorflow dataset\n",
    "all_encoded_data = tf.data.Dataset.from_tensor_slices((tweets_padded, speech[\"label\"]))\n",
    "all_encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c22b4ca9",
   "metadata": {
    "id": "bcd17d27-2f20-49da-a6da-901ce828aa27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12810, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144986d6",
   "metadata": {
    "id": "ac9b15d7-0a00-46e0-94bc-6ce1b2d31bba"
   },
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c91c448",
   "metadata": {
    "id": "7a91ed07-b98f-45b6-9d5c-f271f76093c2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, GRU, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e358f8ab",
   "metadata": {
    "id": "798039e1-371e-4cef-aa60-882788050f34"
   },
   "outputs": [],
   "source": [
    "#Train test Split\n",
    "\n",
    "TAKE_SIZE = int(0.7*speech.shape[0]) #Test_size = 0.3\n",
    "\n",
    "train_data = all_encoded_data.take(TAKE_SIZE).shuffle(TAKE_SIZE)\n",
    "train_data = train_data.batch(800)\n",
    "\n",
    "test_data = all_encoded_data.skip(TAKE_SIZE)\n",
    "test_data = test_data.batch(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9939cf48",
   "metadata": {
    "id": "26029f38-9ef7-47f2-b517-56a193a65b55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  196     3    15 ...     0     0     0]\n",
      " [  131   371 11719 ...     0     0     0]\n",
      " [   21   585  5461 ...     0     0     0]\n",
      " ...\n",
      " [   96    97   784 ...     0     0     0]\n",
      " [  301   731   249 ...     0     0     0]\n",
      " [   11    53    63 ...     0     0     0]], shape=(800, 31), dtype=int32) tf.Tensor(\n",
      "[0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1\n",
      " 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0\n",
      " 1 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1\n",
      " 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 1 1 1\n",
      " 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1\n",
      " 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1\n",
      " 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1\n",
      " 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0\n",
      " 0 1 0 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 1 1 0\n",
      " 1 1 0 1 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0\n",
      " 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0\n",
      " 0 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0\n",
      " 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1\n",
      " 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0\n",
      " 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1\n",
      " 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 1 1 1 1 1 1 0], shape=(800,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#Voici un batch \n",
    "for review, star in train_data.take(1):\n",
    "    print(review, star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7228e2b3",
   "metadata": {
    "id": "99cffc34-7fb7-462b-a87e-f42b78d89dff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "#Definition des paramètres du modèle.\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "vocab_size\n",
    "\n",
    "model_lstm = tf.keras.Sequential([\n",
    "                  Embedding(vocab_size+1,120 , input_shape=[review.shape[1]],name=\"embedding\"),\n",
    "                  LSTM(units=64, return_sequences=True), # maintains the sequential nature\n",
    "                  keras.layers.Dropout(rate = 0.1),\n",
    "                  #LSTM(units=32, return_sequences=False), # returns the last output\n",
    "                  #tf.keras.layers.Bidirectional(LSTM(32,activation='relu',kernel_regularizer='l2')),\n",
    "                  tf.keras.layers.Bidirectional(LSTM(32,activation='relu',kernel_regularizer='l2')),\n",
    "                  keras.layers.Dropout(rate = 0.4), \n",
    "                  Dense(16, activation='relu'),\n",
    "                  Dense(8, activation='relu'),\n",
    "\n",
    "                  Dense(2, activation=\"softmax\", name=\"last\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2454cc8e",
   "metadata": {
    "id": "30f201eb-1342-4c9f-82fe-c8ca0022faee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 31, 120)           2118480   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 31, 64)            47360     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 31, 64)            0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               24832     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " last (Dense)                (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,191,866\n",
      "Trainable params: 2,191,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "344a4c5b",
   "metadata": {
    "id": "37d348e2-b95f-4839-8261-ba22b97e344e"
   },
   "outputs": [],
   "source": [
    "#Choix d'un optimizer, d'une metric et d'une loss function\n",
    "optimizer= tf.keras.optimizers.Adam(0.001)                                  # réduction du learning rate pour diminuer le surapprentissage et donc apprendre moin vite\n",
    "model_lstm.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), #Classification binaire \n",
    "              metrics=tf.keras.metrics.SparseCategoricalAccuracy())#Integer labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df19d03d",
   "metadata": {
    "id": "p_QY2ttyz4ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model/Hatespeech.h5\", monitor='val_sparse_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e9fc2aa",
   "metadata": {
    "id": "3ded8189-f293-4fdf-bce9-87312b64390c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 2.2578 - sparse_categorical_accuracy: 0.5104\n",
      "Epoch 00001: val_sparse_categorical_accuracy improved from -inf to 0.73484, saving model to model\\Hatespeech.h5\n",
      "12/12 [==============================] - 9s 393ms/step - loss: 2.2578 - sparse_categorical_accuracy: 0.5104 - val_loss: 2.0736 - val_sparse_categorical_accuracy: 0.7348\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.9460 - sparse_categorical_accuracy: 0.6843\n",
      "Epoch 00002: val_sparse_categorical_accuracy improved from 0.73484 to 0.81785, saving model to model\\Hatespeech.h5\n",
      "12/12 [==============================] - 4s 315ms/step - loss: 1.9460 - sparse_categorical_accuracy: 0.6843 - val_loss: 1.7724 - val_sparse_categorical_accuracy: 0.8179\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.5961 - sparse_categorical_accuracy: 0.8517\n",
      "Epoch 00003: val_sparse_categorical_accuracy improved from 0.81785 to 0.87848, saving model to model\\Hatespeech.h5\n",
      "12/12 [==============================] - 4s 320ms/step - loss: 1.5961 - sparse_categorical_accuracy: 0.8517 - val_loss: 1.3149 - val_sparse_categorical_accuracy: 0.8785\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0639 - sparse_categorical_accuracy: 0.9280\n",
      "Epoch 00004: val_sparse_categorical_accuracy improved from 0.87848 to 0.87874, saving model to model\\Hatespeech.h5\n",
      "12/12 [==============================] - 4s 346ms/step - loss: 1.0639 - sparse_categorical_accuracy: 0.9280 - val_loss: 1.0622 - val_sparse_categorical_accuracy: 0.8787\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7959 - sparse_categorical_accuracy: 0.9603\n",
      "Epoch 00005: val_sparse_categorical_accuracy improved from 0.87874 to 0.88316, saving model to model\\Hatespeech.h5\n",
      "12/12 [==============================] - 4s 320ms/step - loss: 0.7959 - sparse_categorical_accuracy: 0.9603 - val_loss: 0.9351 - val_sparse_categorical_accuracy: 0.8832\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6056 - sparse_categorical_accuracy: 0.9832\n",
      "Epoch 00006: val_sparse_categorical_accuracy improved from 0.88316 to 0.88655, saving model to model\\Hatespeech.h5\n",
      "12/12 [==============================] - 4s 313ms/step - loss: 0.6056 - sparse_categorical_accuracy: 0.9832 - val_loss: 0.9255 - val_sparse_categorical_accuracy: 0.8865\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4807 - sparse_categorical_accuracy: 0.9913\n",
      "Epoch 00007: val_sparse_categorical_accuracy did not improve from 0.88655\n",
      "12/12 [==============================] - 4s 318ms/step - loss: 0.4807 - sparse_categorical_accuracy: 0.9913 - val_loss: 0.8009 - val_sparse_categorical_accuracy: 0.8709\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3860 - sparse_categorical_accuracy: 0.9945\n",
      "Epoch 00008: val_sparse_categorical_accuracy did not improve from 0.88655\n",
      "12/12 [==============================] - 4s 313ms/step - loss: 0.3860 - sparse_categorical_accuracy: 0.9945 - val_loss: 0.9804 - val_sparse_categorical_accuracy: 0.8678\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3122 - sparse_categorical_accuracy: 0.9967\n",
      "Epoch 00009: val_sparse_categorical_accuracy did not improve from 0.88655\n",
      "12/12 [==============================] - 4s 310ms/step - loss: 0.3122 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.9493 - val_sparse_categorical_accuracy: 0.8756\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2482 - sparse_categorical_accuracy: 0.9974\n",
      "Epoch 00010: val_sparse_categorical_accuracy did not improve from 0.88655\n",
      "12/12 [==============================] - 4s 326ms/step - loss: 0.2482 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.7610 - val_sparse_categorical_accuracy: 0.8689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ba697abbb0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrainement du modèle LSTM\n",
    "model_lstm.fit(train_data,\n",
    "              epochs=10, \n",
    "              validation_data=test_data,\n",
    "              callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c0ab0b9",
   "metadata": {
    "id": "1798f569-5b2f-41ac-87a8-a4c7882b56ed"
   },
   "outputs": [],
   "source": [
    "history = model_lstm.history.history, open(\"LSTM_history.json\", 'w'); #Sauvegarde de l'historique du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "208baad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvh0lEQVR4nO3dd3xUdfb/8deho/QiqICwyqKI0gLqggULYFmxKzZUkJ/Y/a5rWRui7trWtRfE3jtiBTtWJCBYYFVEFBAlgIpYgMj5/XGGZcAQQjKTm2Tez8djHpm5986dk4HMmftpx9wdERGRNVVLOgAREamYlCBERKRIShAiIlIkJQgRESmSEoSIiBSpRtIBZFKzZs28bdu2SYchIlJpTJo0aYG7Ny9qX5VKEG3btiU/Pz/pMEREKg0z+2pt+9TEJCIiRVKCEBGRIilBiIhIkZQgRESkSEoQIiJSJCUIEREpUtYShJm1NrPXzGyamX1iZqcVccwRZvahmX1kZu+YWee0fbNS26eYmcauioiUs2xeQRQCf3P3jsD2wElm1nGNY74Ednb3bYBLgJFr7O/j7l3cPS+LcXLppfDBB9l8BRGRyidrCcLd57n75NT9n4DpwKZrHPOOu3+fevge0Cpb8azNwoUwciTsvDO89lp5v7qISMVVLn0QZtYW6ApMKOawwcALaY8dGGdmk8xsaDHnHmpm+WaWX1BQsN6xNW0Kb78NrVtD//7w+OPrfQoRkSop6wnCzOoBTwCnu/vitRzTh0gQZ6dt7u3u3YA9ieapnYp6rruPdPc8d89r3rzI5UTWqXVrePNNyMuDQw6BW24p1WlERKqUrCYIM6tJJIcH3P3JtRyzLTAKGODuC1dud/e5qZ/zgaeAntmMtUkTeOkl2HtvOPFEuOgiUDVWEcll2RzFZMAdwHR3v2Ytx7QBngSOcvfP0rZvaGb1V94H+gIfZyvWlTbYAJ56Co49FkaMgGHD4Pffs/2qIiIVUzZXc+0FHAV8ZGZTUtv+AbQBcPdbgQuBpsDNkU8oTI1YagE8ldpWA3jQ3V/MYqz/U6MG3HEHtGgBl18OBQXwwANQp055vLqISMVhXoXaUfLy8jyTy31fey2ccQbstBM8/TQ0apSxU4uIVAhmNmltUwk0k7oYp58ODz4I774bw2DnzUs6IhGR8qMEsQ4DB8Kzz8IXX8Bf/gKffbbu54iIVAVKECXQt29MoluyBHr1gokTk45IRCT7lCBKqEePmFBXrx706RNDYkVEqjIliPXw5z9Hkth885gv8dBDSUckIpI9ShDraZNN4I03YIcd4PDD4brrko5IRCQ7lCBKoVEjGDsW9t8/Rjqde65mXYtI1aMEUUp16sBjj8HQoTGhbvBgKCxMOioRkczJ5kzqKq96dbj1VmjZMpbmKCiARx6JJTtERCo7XUGUkRlcfDHcfDM89xzssQcsWpR0VCIiZacEAXDPPfD112U6xbBh8OijkJ8PO+4Ic+ZkKDYRkYQoQSxcGD3N228PU6aU6VQHHQQvvgizZ8es6+nTMxKhiEgilCCaNo1qQdWrx1f/sWPLdLo+fWIY7LJl0Lt3rOMkIlIZKUEAdOoE7723agbcHXeU6XRdu8I770DjxrDbbtE3ISJS2ShBrLTppjB+POy+OwwZAhdeWKbJDX/6U8y63morGDAA7r03g7GKiJSDbFaUa21mr5nZNDP7xMxOK+IYM7PrzWyGmX1oZt3S9g0ys89Tt0HZinM1DRrAM8/AccfBJZfAMcdEW1EptWgRi/ztsgsMGgRXXaUJdSJSeWRzHkQh8Dd3n5wqHzrJzF5y92lpx+wJtE/dtgNuAbYzsybARUAe4KnnjnH377MYb6hZE0aNgrZt4ypi7lx44glo2LBUp2vQIJqYjj4azjoLvv02EkU1XbuJSAWXtY8pd5/n7pNT938CpgObrnHYAOBeD+8BjcxsY6Af8JK7L0olhZeA/tmK9Q/M4IIL4O67o8e5d+8YmlRKtWvHwn6nnALXXBPJogwXJiIi5aJcvseaWVugKzBhjV2bAumfvHNS29a2vXwNGgQvvABffRWr802dWupTVasWC/tddlnUuN5336gvISJSUWU9QZhZPeAJ4HR3X5yF8w81s3wzyy8oKMj06aPT+q234v6OO8K4caU+lRn84x9w++1RT2LXXWN5DhGRiiirCcLMahLJ4QF3f7KIQ+YCrdMet0ptW9v2P3D3ke6e5+55zZs3z0zga9p22xgG265dDIO9664ynW7IEHjySfjoo2i9+uqrDMUpIpJB2RzFZMAdwHR3v2Yth40Bjk6NZtoe+NHd5wFjgb5m1tjMGgN9U9uS06pVTKjr0ydGOQ0fXqYhSQMGxMXI/Pkx6/qjjzIXqohIJmTzCqIXcBSwq5lNSd32MrMTzOyE1DHPAzOBGcDtwIkA7r4IuASYmLqNSG1L1sohScccEyv0HXccLF9e6tPtuGNMvVh5/803MxOmiEgmmFehgfl5eXmen5+f/RdyjwRx8cWxfOvjj0fyKKWvvoJ+/WDWrGh62muvzIUqIlIcM5vk7nlF7dNo/NIwiyamO++MmXBlXL51s82iH7xjRzjggDL1g4uIZIwSRFkce2w0OX35ZawG++GHpT5Vs2YxsmnLLaN/4pVXMhiniEgpKEGUVd++0XngHlcSL79c6lM1bRpP32IL+Otf4fXXMxemiMj6UoLIhM6dYxhsmzaw555RgKiUmjWLq4d27WCffdRxLSLJUYLIlNatoyNh551jlNOIEaUeBrvRRpEkWrWKDut33slsqCIiJaEEkUkNG8Lzz8diSxddFDPiSjkMtmVLePVV2Hhj6N8fJqy5SImISJYpQWRarVqxyN+FF8Yop332gcWlW2Fkk00iSTRvHsNgy2MEr4jISkoQ2WAWcyRGjYq2op12gm++KdWpWrWKkbSNG0d/+AcfZDhWEZG1UILIpsGDYxjsF1/EMNiPPy7Vadq0iSRRr16sHViG0bQiIiWmBJFt/frFUKTCQujVK9qMSqFt20gSdetGnetS5hoRkRJTgigPXbrEMNjWraPH+b77SnWazTePJFGzZiSJ6dMzG6aISDoliPLSpk0Mg+3dO0Y5XXZZqYbBtm8fScIs6kl8+mkWYhURQQmifDVqBC++CEceCeefD0OHlmoYbIcO0VL1+++RJGbMyHyoIiJKEOWtVi24914477wY5bTvvvDTT+t9mo4dI0ksXRolKmbOzEKsIpLTlCCSYAaXXgojR8YKfTvvXKphsJ06xSjaX36JJDFrVuZDFZHcpQSRpOOPh2eegc8+gx12gE8+We9TdO4cOWbx4mhumj07C3GKSE7KZsnRO81svpkVOSDTzP6eVmnuYzP73cyapPbNMrOPUvuq9vzhPfeMsnLLlsUw2EmT1vsU3bpFDYmFC+NKYm6R1btFRNZPNq8g7gb6r22nu1/l7l3cvQtwLvDGGmVF+6T2F1npqErp1i2GwTZoAAcfDD/8sN6n6NEDxo6NGtd9+sC8eZkPU0RyS9YShLuPB0paR3og8FC2YqkUNtsMHn002ogGDy7VENjtt4cXXojujF13he++y0KcIpIzEu+DMLMNiCuNJ9I2OzDOzCaZ2dB1PH+omeWbWX5BQUE2Q82+7beHK66IwtQ33FCqU/TqFQvKfv11JInK/paISHISTxDAX4G312he6u3u3YA9gZPMbKe1PdndR7p7nrvnNW/ePNuxZt8ZZ0Q5uTPPhIkTS3WKnXaCZ5+NSqi77QYLFmQ4RhHJCRUhQRzGGs1L7j439XM+8BTQM4G4kmEWy4Vvsgkccgh8/32pTtOnD4wZA59/DnvsAYtK2tgnIpKSaIIws4bAzsDTads2NLP6K+8DfYHcWpquSRN45BGYMweOO67Ulel23x1Gj4Zp02Kp8FL0fYtIDsvmMNeHgHeBDmY2x8wGm9kJZnZC2mH7A+Pc/ee0bS2At8xsKvA+8Jy7v5itOCus7baDK6+MT/jrry/1afr1iy6NDz+M+z/+mLkQRaRqMy/lt9OKKC8vz/OrUtk1d9h//+h1fust6Fn6lrYxY+DAA1cNh61fP4NxikilZWaT1jadoCL0QcjamMFdd5W5PwJiyadHHoH334e99oIlSzIYp4hUSUoQFV3jxjE/4ptv4NhjS90fAXDAAfDgg/DOO1Eq++ef1/0cEcldShCVQc+ecNVV8PTTcO21ZTrVIYdEvaI334yril9/zUyIIlL1KEFUFqeeGv0RZ50FEyaU6VSHHx4jaV97DfbbD377LSMRikgVowRRWZjBnXdCq1ZxGVDGiQ1HHQV33BGL/B1wQNSVEBFJpwRRmTRqFP0R8+bBMceUqT8Coktj5MhYv+mgg2JBWRGRlZQgKpsePeDqq6OOxDXXlPl0xx8PN98cS3McemipKqCKSBWlBFEZnXJKtAudcw68+26ZTzdsWMzFGz06+icKC8seoohUfjWSDkBKwSw6ELp1i6/9U6bE8hxlcMopkRj+7/+gRg24/36oXj0z4YpI5aQriMqqUSN47LEo+jBoEKxYUeZTnnEGXH45PPww3HRT2UMUkcpNCaIy694d/v3v6EDIQH8ExCjaPfeEc8+FWbMyckoRqaSUICq7k06KIUjnnBNTpMvIDG69FapVg//3/8o8UEpEKjEliMrODEaNipKlhx4KCxeW+ZRt2kRT07hxcO+9GYhRRColJYiqoGHDmB8xfz4cfXRG+iOGDYvypWecodrWIrlKCaKq6N49+iGefz7mSZRRtWpxYfLzz7HKh4jkHiWIquTEE+Hgg+Ef/4C33y7z6bbcEi68MC5Onn563ceLSNWSzYpyd5rZfDMrslyome1iZj+a2ZTU7cK0ff3N7FMzm2Fm52QrxirHDG6/Hdq2jf6IBQvKfMqzzoJtt43co2p0Irklm1cQdwP913HMm+7eJXUbAWBm1YGbgD2BjsBAM+uYxTirloYNY35EQUFG+iNq1ow5ed9+G8lCRHJH1hKEu48HSrPkaE9ghrvPdPdlwMPAgIwGV9V17Rp1I154Iepal1FeXsywHjkSXn+9zKcTkUoi6T6IHcxsqpm9YGZbp7ZtCsxOO2ZOaluRzGyomeWbWX5BQUE2Y61cTjghmpnOPz+qA5XRxRfD5pvH4n6//JKB+ESkwksyQUwGNnP3zsANwOjSnMTdR7p7nrvnNW/ePJPxVW5m8ZW/XTsYODCanMpggw2ie2PGDBg+PDMhikjFlliCcPfF7r4kdf95oKaZNQPmAq3TDm2V2ibrq0GD6I9YsCAqBJWxP6JPHxgyJFb3mDQpQzGKSIWVWIIws5ZmZqn7PVOxLAQmAu3NrJ2Z1QIOA8YkFWel16ULXHcdjB0LV1xR5tNddRW0aAGDB6t2hEhVl81hrg8B7wIdzGyOmQ02sxPM7ITUIQcBH5vZVOB64DAPhcDJwFhgOvCou3+SrThzwtChcNhh0R8xfnyZTtWoURQYmjo1koWIVF3mVWg1try8PM/Pz086jIpp8eIYjvTzz/DBB7DRRmU63cEHR1G7qVOhQ4cMxSgi5c7MJrl7XlH7kh7FJOVlZX/EwoUZ6Y+44YbouB4yJCNLP4lIBaQEkUs6d47aouPGwb/+VaZTtWwZSz+99VYsDy4iVY8SRK45/vgoPH3hhfDGG2U61aBBsMcecPbZMHv2uo8XkcpFCSLXrKwItMUWMT+iDGt5m8Ftt0UT07BhKi4kUtUoQeSi+vWjP+L77+HII+H330t9qnbt4LLL4Lnn4KGHMhijiCROCSJXbbtt9DS//HKZ+yNOOQW22w5OO63ME7ZFpAJRgshlgwfDEUfARRfBa6+V+jTVq0dxoR9/hNNPz1x4IpIsJYhctrI/on376LguQ39Ep05Rp+jBB6O5SUQqPyWIXFevXvRH/PBDXE2UoT/i3HOhY8fosF68OHMhikgylCAEttkGbrwRXnklepxLqXbtKC40Z04kCxGp3JQgJBx3XMywHj4cXn211KfZfns49dRYr+mttzIXnoiUP63FJKssWQI9esTw17FjY+Z1KU/TqRPUqQNTpsRPEamYyrwWk5mdZmYNLNxhZpPNrG9mw5TE1asHTzwB1arFuNWbbirV7Ld69aJW0aefwiWXZCFOESkXJW1iOs7dFwN9gcbAUcDlWYtKktOxYyzRuuuucPLJcOCBsGj9S4v37RtLcVx5ZVxFiEjlU9IEYamfewH3peozWDHHS2XWvDk8+2yUjnv2WejaFd5+e71Pc8010KRJTLcoLMxCnCKSVSVNEJPMbByRIMaaWX2g2EWezexOM5tvZh+vZf8RZvahmX1kZu+YWee0fbNS26eYmToVklCtGvzf/0ViqFEDdt4Z/vnP9RoG26RJDI6aPBn+858sxioiWVHSBDEYOAfo4e6/ADWBY9fxnLuB/sXs/xLY2d23AS4BRq6xv4+7d1lb54mUkx49osDQwQfDeedBv37w7bclfvpBB8GAAbF47IwZWYxTRDKupAliB+BTd//BzI4Ezgd+LO4J7j4eWGvjtbu/4+7fpx6+B7QqYSxS3ho0iCnSo0bBO+/E6KaxY0v0VLMY8lq7dqw0XoUGzYlUeSVNELcAv6Sagf4GfAHcm8E4BgMvpD12YJyZTTKzocU90cyGmlm+meUXaKW47DGLzoT8/ChX2r9/FIJYvnydT91kk6hf/frrkWNEpHIoaYIo9JgwMQC40d1vAupnIgAz60MkiLPTNvd2927AnsBJZrbT2p7v7iPdPc/d85o3b56JkKQ4HTvC++/DCSfEEKUdd4Qvv1zn04YMgV12gTPPhLlzsx+miJRdSRPET2Z2LjG89Tkzq0b0Q5SJmW0LjAIGuPvCldvdfW7q53zgKaBnWV9LMqhuXbjlFnj0Ufjvf6FLl1jPqRhmcPvtsGwZnHSSmppEKoOSJohDgaXEfIhvif6Cq8rywmbWBngSOMrdP0vbvmFqlBRmtiEx96LIkVCSsIMPjg7srbaCQw6Jq4pff13r4VtsASNGwNNPw+OPl2OcIlIqJV5qw8xaAD1SD99Pfbsv7viHgF2AZsB3wEWkrjrc/VYzGwUcCHyVekqhu+eZ2Z+IqwaAGsCD7l6iFeS01EZCli+HCy6AK66ArbeGRx6Jn0UoLIz1mmbPhmnToGnTco5VRFZT3FIbJUoQZnYIccXwOjFBbkfg7+5eob4HKkEkbNy4WPDvp5/g+uujU9v+OJ9y6lTIy4vVxe++u/zDFJFVyrwWE3AeMQdikLsfTfQJXJCpAKWK6Ns3Pv179YoxrQMHRpm5NXTuDGedBffcEzlFRCqmkiaIams0KS1cj+dKLmnZMuZI/Otf0dHQtWuMelrDBRdAhw4wdGis/ioiFU9JP+RfNLOxZnaMmR0DPAc8n72wpFKrVg3OOQfGj4+lOXr1inWdVqxanaVOnZgT8dVXcP75CcYqImtVogTh7n8nlsLYNnUb6e5nF/8syXl/+Uss5brvvjEBYp99IG0yY+/ecOKJ0V3x3nvJhSkiRVPBIMk+d7j1VjjjjFjB7/77YzlxonZ1p05Qv34s6le7dsKxiuSYUndSm9lPZra4iNtPZqay9FIyZjBsWPRFNGwIu+8enRCFhTRoELlj2rTothCRiqPYBOHu9d29QRG3+u7eoLyClCpi221jLadjj4VLL4U+fWD2bPbaCw4/PFYT/1hTIkUqDI1EkvK14YZwxx3wwAPRP9G5Mzz9NNdeGxcXQ4asV8kJEckiJQhJxuGHxzId7drBfvvR/JJTueGq35gwAW64IengRASUICRJW2wR9SXOOANuuIFDr9uB43f+jPPOK9ECsSKSZUoQkqzataN49TPPYLNnc+vEbhyx4j6GDtWKryJJU4KQimGffWDqVKr1yGPkb0dz5MuDeOA2TbEWSZIShFQcm24Kr7zCiouGcyT3s9OJW/PfIy6BWbOSjkwkJylBSMVSvTrVhl/Ewsde47sNN2fLBy+Edu3wnXeBu+6KlWJFpFwoQUiFtNFBO7FNwaucdcgszucS5uZ/A8cdBy1awJFHwksvaTysSJYpQUiFVacOXPnIZrS9/Xy2KPyU/Vu8w/z+R8Nzz8XS4pttFosCTp+edKgiVVJWE4SZ3Wlm882syPmxFq43sxlm9qGZdUvbN8jMPk/dBmUzTqnYhgyBt942JtfegdbP3cqdl83DH3k0amFffTV07Ag9e8KNN8LChes8n4iUTLavIO4G+hezf0+gfeo2FLgFwMyaECVKtyOKE11kZo2zGqlUaHl5MGkS7LILDD6pDkPGHsyvjz0Lc+fGMNlly+CUU2DjjeGAA2D06NgmIqWW1QTh7uOBRcUcMgC418N7QCMz2xjoB7zk7ovc/XvgJYpPNJIDmjWD55+Pdf7uvDPKTHz5S4uYaDdlStxOOSUm3+2/f4yKOvXUWP9JkypE1lvSfRCbArPTHs9JbVvb9j8ws6Fmlm9m+QVptQakaqpeHUaMgGeegZkzoXt3eOGF1M7OnaMw0Zw50U+x664wciT06BFril95ZVxxiEiJJJ0gyszdR7p7nrvnNW/ePOlwpJzss080ObVpA3vvDRdfnFawrkYN2GsveOQRmDcPbrsNGjWCs8+OJ/TrF4sF/vJLkr+ClMayZXDzzfHNoHdvOPDAqDp18cXx7zx6NLz7bnx7+PnnpKOt9Gok/PpzgdZpj1ults0Fdllj++vlFpVUCptvHq1Jw4bB8OEwYULUImrSJO2gxo2j8PXQofD553DffXDvvTFUtn59OPhgOPpo2HHHKJUqFdPvv8c/7vDhMXEyLw9q1YL//hfeeGPtgxM23DCGRrdsGT/XdmvZEurVK8/fqFLIekU5M2sLPOvunYrYtzdwMrAX0SF9vbv3THVSTwJWjmqaDHR39+L6M1RRLke5x5fHU0+Nbocnn4SuXYt5wooV8OabcM898NhjsGQJtG0bieKoo2IRQakYVqyIf9ALL4zhzN27w2WXxTBns1XHLV8O8+fDd9/98fbtt6s/Xriw6D6pDTZYdxJZeb9+/dVfvxIrrqJcVhOEmT1EXAk0A74jRibVBHD3W83MgBuJDuhfgGPdPT/13OOAf6ROdZm737Wu11OCyG0TJsBBB8GCBdEKceyxJXjSzz/DU0/FVcXLL8cHR69eMGhQXF00apTtsKUo7jB2LJx3XtSi3WqrKDK1//5l/2AuLIza6EUljzUTy4IFRSeTOnUiUWyxBZx7Luy2W9liSlBiCaK8KUFIQQEcdhi8+mq0Kl13Xfwtl8icOdE3cc898W21dm3Yb7/4469bNx7XqRM/17wVtb1mzSrzLbNcvflmJIY334x6IcOHwxFHxAiF8lZYGElibVcl48fD119D//5wxRVRNbGSUYKQnFJYGENhL788mqoffzwmXZeYewyNvfdeePBBWFRsy+bamUU7+dqSyvoknDp1YmLgbrsl80FZHiZNgvPPhxdfjPksF1wAgwfHe1hR/fYb3HRTXN38+GNceV5yCbRqlXRkJaYEITlp9Oj4e61ZEx56CPbYoxQnWbYsvi0uXRq3335bdT/9trbtmXhO+ppTLVtGNb6jjophvVXhCmXatOhjeOKJGGFwzjlw0knRJ1BZLFoE//oXXH99DHY444wYNdewYdKRrVNxCQJ3rzK37t27u0i6zz5z79TJ3cz90kvdf/896YhKobDQffFi9yeecN9vP/eaNd0hfrErrnCfPTvpCEtn5kz3QYPcq1Vzr1/f/aKL3H/8MemoyubLL92POCL+fZo2db/uOvelS5OOqlhAvq/lMzXxD/VM3pQgpChLlrgffnj8b//rX92//z7piMpowQL3m29232GH+KXM3Hfd1f2uuyKRVHTffON+4omR6OrUcT/zTPeCgqSjyqxJk+LfBNw339z90UfdV6xIOqoiKUFIzluxwv2GG9xr1Ii/16lTk44oQ2bMcB8+PH4pcK9b1/2ww9yfe859+fKko1vdggXuf/97xFijhvuwYe5z5iQdVfasWOH+wgvu22wT/zY9e7qPH590VH+gBCGS8vbb7ptsEp9R99677uMrjRUr3N95J76ZN2kSf9obbeR+2mnu+fnJfnv98cdIYvXrx9XOUUe5f/FFcvGUt8JC9zvvdN900/h32Xdf92nTko7qf5QgRNJ8+637zjvH//4TT6zwTcTrb+lS99Gj3Q880L1WrfhFt9rK/bLL3GfNKr84fvnF/eqroy0e3A84wP3jj8vv9Suan392/+c/I1FWq+Y+dKj7vHlJR6UEIbKm5cuj6Rvct9++8vbzrtOiRe4jR7rvuGP8shDZ8fbb3X/4ITuvuWyZ+y23xKUauPfr5z5xYnZeqzKaP9/91FOjmW3DDaNz/qefEgtHCUJkLR57zL1ePffmzd1feSXpaLJs5kz3Sy5x//Of40+/dm33gw92HzMmPtTLqrAw2u3+9Kc4f69e7q+/XvbzVlWffx7vP7i3aBFJNYF+IyUIkWJMnx4tMNWqxajRCjrYJHNWrHB//333U05xb9YsPgaaNXM/+WT3995b/zdgxQr3J59079gxztW1q/vzz+fAG5kh773n3rt3vHcdOkTzYDm+d0oQIuvw00/uhxwSfxH771/5h+OX2LJl7s88437ooTHkFOIKY8SIuOIozooV7mPHuuflrfpwe/TRSjrZJGErVrg//bT7llvGe9m7t/u775bLSytBiJTAihXu11zjXr16fEbmXH/qDz+433GH+y67+P/6K3r1cr/11ujLSPfWW6t6+jfbLOZgVLRhtZXR8uXxfrdoEe/tQQfFbM8sKi5BaKkNkTWMHw+HHgqLF8OoUTBwYNIRJeDrr2Mdqvvui6UwatWKKk377guPPhq1X1u0iPWShgyJ9aIkc5YsieqIV10Vy60MGxbvdRaKomktJpH1NG8eHHIIvPVWrAp72WVREzvnuMMHH0SieOihWMG0ceNYZ+jkk6Mgj2TPvHlRLW/UqFib6pxz4PTTM7pOlRKESCksXx5L/f/nP1Fs7LzzoihRiZcPr2oKC2PF1Q4dVCejvE2fHv8Zn34aNtkkVowdNCgjK/sWlyCyWmPRzPqb2admNsPMzili/3/MbErq9pmZ/ZC27/e0fWOyGadIUWrWhKuvho8+ioqkZ58dn40PPJBW/zqX1KgB222n5JCErbaK5YnHj4fWrWMZ9C5d4IUXii5olCFZSxBmVh24CdgT6AgMNLOO6ce4+xnu3sXduwA3AE+m7f515T533zdbcYqsS8eO8Oyz8Mor0LRplLPu2RNefz3pyCTn7LgjvPtu9AP9+ivstRfsvntc2WVBNq8gegIz3H2muy8DHgYGFHP8QOChLMYjUia77rqqjtB330GfPtFnO3160pFJTjGLcrjTpkX9iQ8/jBrdv/yS8ZfKZoLYFJid9nhOatsfmNlmQDvg1bTNdcws38zeM7P9shalyHqoVi1q9Xz2WdSHef112GabGGTy3XdJRyc5pVYtOOUUmDEjmp+yUGApq30Q6+Ew4HF3TyudxWapjpPDgWvNbPOinmhmQ1OJJL+goKA8YhWhbt0YUPLFF3DCCXD77VG//rLLsvJFTmTtGjaMpqcsyGaCmAu0TnvcKrWtKIexRvOSu89N/ZwJvA50LeqJ7j7S3fPcPa95FsYIixSneXO48Ub45JNoCj7/fPjzn+Huu1evFCpSGWUzQUwE2ptZOzOrRSSBP4xGMrMtgcbAu2nbGptZ7dT9ZkAvYFoWYxUpkw4d4KmnYpDJJpvAscdC9+7w8stJRyZSellLEO5eCJwMjAWmA4+6+ydmNsLM0kclHQY87KtPyNgKyDezqcBrwOXurgQhFd6OO8J778Wcsh9/hD32gD33hI8/TjoykfWniXIiWbJ0aTQ/XXppLNtx3HEwYgRsvHHSkYmskthEOZFcVrs2/O1vMcjk1FPhnnuiI3v48FhqR6SiU4IQybKmTWO5junTYe+9Y2md9u1jeR11ZEtFpgQhUk423zwmwL79NrRrB8cfD507Z321BJFSU4IQKWd/+Uskiccfh99+i9US+vaFKVOSjkxkdUoQIgkwgwMPjNUSrr0WJk+Gbt3gmGNgzpykoxMJShAiCapVC047LWZkn3lmDI9t3z4m3C1enHR0kuuUIEQqgEaN4Mor4dNPYf/9Y8mOLbaAW26JuhQiSVCCEKlA2raNSp/vvx8lAE48MRYDHDNGHdlS/pQgRCqgHj1ipdjRo+PxgAHQtStcc01UoRQpD0oQIhWUWSSGjz6C226L/oq//Q1atYL+/aOy3c8/Jx2lVGVKECIVXM2aMHRoNDutLE383/9GZbsWLaI08UsvadKdZJ4ShEglsuWWsbbTzJnwxhswcGDUse/bF9q0gb//PQqMiWSCEoRIJVStGuy0UxQq+vbbmKHdvXvMqejcOW7//rf6K6RslCBEKrk6daJE8Zgx8M03cMMNse3MM6O/ol8/uP9+LRAo608JQqQKad4cTj4ZJkyIfop//CPqZx91FLRsGT/HjVN/hZSMEoRIFdWhA1xySczSHj8eDj8cnnkmrihat44rjKlTk45SKrKsJggz629mn5rZDDM7p4j9x5hZgZlNSd2GpO0bZGafp26DshmnSFVWrVpUuhs5MvorHnss5llcdx106QLbbgtXXRXNUyLpslZRzsyqA58BewBziBrVA9NLh5rZMUCeu5+8xnObAPlAHuDAJKC7u39f3GuqopxIyS1YAI88AvfdF01SZrDbbtEMdcABUK9e0hFKeUiqolxPYIa7z3T3ZcDDwIASPrcf8JK7L0olhZeA/lmKUyQnNWsGJ50UNbQ//TQWCPzii5hX0aJFzLMYO1b9FbksmwliU2B22uM5qW1rOtDMPjSzx82s9Xo+FzMbamb5ZpZfUFCQibhFcs6f/xz1sr/4At58M5LDc8/FjO1WrWIG95QpWg8q1yTdSf0M0NbdtyWuEu5Z3xO4+0h3z3P3vObNm2c8QJFcYga9e8fSHvPmRVGj7baLobNdu0Z/xQUXwFtvaZXZXJDNBDEXaJ32uFVq2/+4+0J3X5p6OAroXtLnikh21akTRY1Gj45kcdNN0LAh/POf0endrFksTX7rrTGzW6qebHZS1yA6qXcjPtwnAoe7+ydpx2zs7vNS9/cHznb37VOd1JOAbqlDJxOd1IuKe011Uotk3w8/wCuvxHyKsWPhq69i+xZbxJIf/fpBnz5Qv36iYUoJFddJXSNbL+ruhWZ2MjAWqA7c6e6fmNkIIN/dxwCnmtm+QCGwCDgm9dxFZnYJkVQARqwrOYhI+WjUKK4sDjww+iQ+/zwSxbhxcM89cPPNUKNG1N5emTC6dYvhtlK5ZO0KIgm6ghBJ1tKl8O67qxLG5MmxvWlT2GOPSBh9+8KmRQ45kSQUdwWhBCEiWTN/Prz88qqE8e23sX3rrePKom/fWHSwbt1k48xlShAikjj3KH60su/izTfjiqN27UgSKxNGp04xmkrKhxKEiFQ4v/wSa0StTBjTUmssbLzxqr6L3XePBQgle5QgRKTCmzMnksW4cVEhb9GiuJLo1m1Vwthhhyi9KpmjBCEilcrvv0cH98q+i3ffhcLCWB+qT5/o8O7VC7bZJkqySukpQYhIpbZ4Mbz2WiSMsWNXTcyrWzeuMLbbbtWtTRv1YawPJQgRqVJmzYpFBidMiNvkydHhDbHQYHrC6NEDGjRINNwKLZGJciIi2dK2bdwOOyweL1sWI6RWJowJE6IEK8TVxFZbrZ40OnWKyXxSPF1BiEiV9P33MHHi6kljwYLYt8EG0L079Oy5Kmm0bp2bTVNqYhKRnOcOX365esL44INVTVMtW/6xaSoX1pNSE5OI5Dwz+NOf4jZwYGxbtizqcqcnjaefXnV8x46rJ42tt86tpildQYiIpFm0CN5/P24rk8bChbFvgw0gL29VwujZMwoqVeamKTUxiYiUknsMq12zaWrZstjftCl07gxdusStc+foFK8s8zOUIEREMmjp0miamjgxfk6ZEqOofvst9teqFc1T6Umjc2do3DjBoNdCCUJEJMsKC6M2xpQpq5LGlCnw3Xerjtlss1VXGyt/tmuXbBOVOqlFRLKsRo1oWtpqq1Wd4BBLnE+dunrSePZZWLEi9jdoELW+0682tt66YiyBntUrCDPrD1xHVJQb5e6Xr7H//4AhREW5AuA4d/8qte934KPUoV+7+77rej1dQYhIZfDrr/Dxx6snjQ8/hJ9+iv3Vq0OHDqsnjS5dYKONMh9LIk1MZladqEm9BzCHKB860N2npR3TB5jg7r+Y2TBgF3c/NLVvibvXW5/XVIIQkcpqxYqYp5GeNKZOha+/XnVMy5Z/TBrt20dCKa2kmph6AjPcfWYqiIeBAcD/EoS7v5Z2/HvAkVmMR0SkwqpWDTbfPG4HHLBq+6JFqzdRTZ0K//43LF8e++vWjVnh48dnvi8jmwliU2B22uM5wHbFHD8YeCHtcR0zyyeany5399FFPcnMhgJDAdq0aVOWeEVEKpwmTWKJ8z59Vm1btgymT1+VNJYsyU5Hd4XopDazI4E8YOe0zZu5+1wz+xPwqpl95O5frPlcdx8JjIRoYiqXgEVEElSr1qqhs0cfnb3XqZa9UzMXaJ32uFVq22rMbHfgPGBfd1+6cru7z039nAm8DnTNYqwiIrKGbCaIiUB7M2tnZrWAw4Ax6QeYWVfgNiI5zE/b3tjMaqfuNwN6kdZ3ISIi2Ze1JiZ3LzSzk4GxxDDXO939EzMbAeS7+xjgKqAe8JhFA9rK4axbAbeZ2QoiiV2ePvpJRESyTzOpRURyWHHDXLPZxCQiIpWYEoSIiBRJCUJERIqkBCEiIkWqUp3UZlYAfFXKpzcDFmQwnMpM78Xq9H6sTu/HKlXhvdjM3ZsXtaNKJYiyMLP8tfXk5xq9F6vT+7E6vR+rVPX3Qk1MIiJSJCUIEREpkhLEKiOTDqAC0XuxOr0fq9P7sUqVfi/UByEiIkXSFYSIiBRJCUJERIqU8wnCzPqb2admNsPMzkk6niSZWWsze83MppnZJ2Z2WtIxJc3MqpvZB2b2bNKxJM3MGpnZ42b2XzObbmY7JB1TkszsjNTfycdm9pCZ1Uk6pkzL6QRhZtWBm4A9gY7AQDPrmGxUiSoE/ubuHYHtgZNy/P0AOA2YnnQQFcR1wIvuviXQmRx+X8xsU+BUIM/dOxElDQ5LNqrMy+kEAfQEZrj7THdfBjwMDEg4psS4+zx3n5y6/xPxAbBpslElx8xaAXsDo5KOJWlm1hDYCbgDwN2XufsPiQaVvBpAXTOrAWwAfJNwPBmX6wliU2B22uM55PAHYjoza0uUeZ2QcChJuhY4C1iRcBwVQTugALgr1eQ2ysw2TDqopKRKIl8NfA3MA35093HJRpV5uZ4gpAhmVg94Ajjd3RcnHU8SzGwfYL67T0o6lgqiBtANuMXduwI/AznbZ2dmjYnWhnbAJsCGZnZkslFlXq4niLlA67THrVLbcpaZ1SSSwwPu/mTS8SSoF7Cvmc0imh53NbP7kw0pUXOAOe6+8orycSJh5KrdgS/dvcDdlwNPAn9JOKaMy/UEMRFob2btzKwW0ck0JuGYEmNRGPwOYLq7X5N0PEly93PdvZW7tyX+X7zq7lXuG2JJufu3wGwz65DatBuQy3Xivwa2N7MNUn83u1EFO+1rJB1Akty90MxOBsYSoxDudPdPEg4rSb2Ao4CPzGxKats/3P355EKSCuQU4IHUl6mZwLEJx5MYd59gZo8Dk4nRfx9QBZfd0FIbIiJSpFxvYhIRkbVQghARkSIpQYiISJGUIEREpEhKECIiUiQlCJF1MLPfzWxK2i1jM4jNrK2ZfZyp84lkUk7PgxApoV/dvUvSQYiUN11BiJSSmc0ysyvN7CMze9/Mtkhtb2tmr5rZh2b2ipm1SW1vYWZPmdnU1G3l0gzVzez2VG2BcWZWN3X8qanaHB+a2cMJ/ZqSw5QgRNat7hpNTIem7fvR3bcBbiRWfwW4AbjH3bcFHgCuT22/HnjD3TsT6xitnLXfHrjJ3bcGfgAOTG0/B+iaOs8J2fnVRNZOM6lF1sHMlrh7vSK2zwJ2dfeZqUUOv3X3pma2ANjY3Zents9z92ZmVgC0cvelaedoC7zk7u1Tj88Garr7pWb2IrAEGA2MdvclWf5VRVajKwiRsvG13F8fS9Pu/86qvsG9iYqH3YCJqcI0IuVGCUKkbA5N+/lu6v47rCo/eQTwZur+K8Aw+F+t64ZrO6mZVQNau/trwNlAQ+APVzEi2aRvJCLrVjdtdVuIuswrh7o2NrMPiauAgaltpxCV1/5OVGFbuerpacBIMxtMXCkMI6qRFaU6cH8qiRhwvUp8SnlTH4RIKaX6IPLcfUHSsYhkg5qYRESkSLqCEBGRIukKQkREiqQEISIiRVKCEBGRIilBiIhIkZQgRESkSP8feqNlVdmtWk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of the training process on the loss function \n",
    "plt.plot(history[0][\"loss\"], color=\"b\")\n",
    "plt.plot(history[0][\"val_loss\"], color=\"r\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0337d885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.07356858253479,\n",
       " 1.7723661661148071,\n",
       " 1.3149243593215942,\n",
       " 1.0622074604034424,\n",
       " 0.9350911974906921,\n",
       " 0.9254580140113831,\n",
       " 0.8008520007133484,\n",
       " 0.9803551435470581,\n",
       " 0.949288547039032,\n",
       " 0.7609995007514954]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[0][\"val_loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb83d57",
   "metadata": {},
   "source": [
    "## Confusion matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6345beb5-fe8e-491f-8427-d10ceb3d2074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 2.0155330e-08],\n",
       "       [9.9999940e-01, 5.6334244e-07],\n",
       "       [7.2780889e-01, 2.7219111e-01],\n",
       "       ...,\n",
       "       [9.3787014e-01, 6.2129837e-02],\n",
       "       [9.1928965e-01, 8.0710381e-02],\n",
       "       [1.2378968e-06, 9.9999881e-01]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction(s) (1 dim array)\n",
    "predict = model_lstm.predict(test_data, callbacks=[checkpoint], verbose=0)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7b7ab11-3745-4ea5-82dc-34e643abfcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int64, numpy=0>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=0>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=1>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=1>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#True target values\n",
    "test = test_data.unbatch()\n",
    "y = list(zip(*test))\n",
    "y[1][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f1794fd-653b-44a1-a70a-2ef04eb351e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To 1 dimension array -> predictions VS True values\n",
    "predict_class = np.argmax(predict, axis = 1)\n",
    "predict_class = predict_class.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb5472f5-8179-44c9-9f2e-e9838d7d14fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrice\n",
    "cf = tf.math.confusion_matrix(\n",
    "    y[1], predict_class, weights=None, dtype=tf.dtypes.int32,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5effeeb5-bda0-4d6b-9d5e-fcbda315c547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from seaborn) (3.5.0)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from seaborn) (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from seaborn) (1.21.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.28.2)\n",
      "Requirement already satisfied: setuptools-scm>=4 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from matplotlib>=2.2->seaborn) (6.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (1.2.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\conta\\.conda\\envs\\final-project\\lib\\site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (58.0.4)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "import seaborn as sns\n",
    "sns.heatmap(cf, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca615d6-161b-42a2-a5f6-6f8c22e3bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verification according to our training best accuracy !\n",
    "mean_accuracy = (1603 + 1709)/((1603 + 1709) + (211 + 320))\n",
    "print(mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a969e6-2c04-453a-89c2-e90c16880337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ML_Hate_Speech-Dataset_2_projet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
